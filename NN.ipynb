{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyO0JGKpJTbMYik5Xf8ysicL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"4Zr78BbS-5Uj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f6999314-540d-4013-9c58-34e3b163bf5f","executionInfo":{"status":"error","timestamp":1582046400179,"user_tz":-120,"elapsed":31654,"user":{"displayName":"Peter Maged","photoUrl":"","userId":"06037909729134877604"}}},"source":["import tensorflow as tf\n","import csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix\n","import numpy as np\n","import pandas\n","\n","\n","mypath = \"/content/\"\n","X = []\n","Y0= []\n","with open(mypath+\"featureswithout.csv\") as f:\n","    reader = csv.DictReader(f)  # read rows into a dictionary format\n","    for row in reader:  # read a row as {column1: value1, column2: value2,...}\n","        temp = list(row.values())\n","        temp = [float(i) for i in temp]\n","        X.append(temp)\n","for i in range(1):\n","    with open(mypath+\"labels_0.csv\") as f:\n","        reader = csv.DictReader(f)  # read rows into a dictionary format\n","        for row in reader:  # read a row as {column1: value1, column2: value2,...}\n","            temp = list(row.values())\n","            temp = [float(i) for i in temp]\n","            temp2 = temp[0]\n","            if temp2 > 4.5:\n","                Y0.append(1)\n","            else:\n","                Y0.append(0)\n","\n","X0_train, X0_test, Y0_train, Y0_test = train_test_split(X, Y0, test_size=0.2)\n","X_0train, X0_test, Y0_train, Y0_test = train_test_split(X, Y0, test_size=0.2)\n","print(X0_train[0:5])\n","print(Y0_train[0:5])\n","\n","######################################################################################################\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('acc')>0.8):\n","      print(\"\\nReached 80% accuracy so cancelling training!\")\n","      self.model.stop_training = True\n","\n","callbacks = myCallback()\n","\n","X0_train = np.array(X0_train)\n","Y0_train = np.array(Y0_train)\n","X0_test = np.array(X0_test)\n","Y0_test = np.array(Y0_test)\n","\n","X0_train = np.expand_dims(X0_train, axis=2)\n","X0_test = np.expand_dims(X0_test, axis=2)\n","\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv1D(32, (4), activation='relu', input_shape=(160, 1)),\n","    tf.keras.layers.MaxPooling1D(4),\n","    tf.keras.layers.Conv1D(16, (4), activation='relu'),\n","    tf.keras.layers.MaxPooling1D(4),\n","    tf.keras.layers.Conv1D(8, (4), activation='relu'),\n","    tf.keras.layers.MaxPooling1D(4),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","'''model = tf.keras.models.Sequential([\n","  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(1, activation='sigmoid')\n","])'''\n","\n","from tensorflow.keras.optimizers import RMSprop\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=RMSprop(lr=0.0001),\n","              metrics=['acc'])\n","\n","\n","model.fit(X0_train, Y0_train, validation_data=(X0_test, Y0_test), epochs=200)\n","\n","print(\"Arrosal\")\n"],"execution_count":33,"outputs":[{"output_type":"stream","text":["[[2.878578018275749, 6.463632231135088, 11.127421513051504, 22.700636087466393, 13.97876663653458, 3.8267349067979723, 8.342404482630798, 15.163624371221864, 28.310606669990552, 18.144476126619693, 4.35835045058559, 9.440703663118446, 14.959547784370258, 26.641630152274622, 16.899410682655482, 1.6842102757526443, 4.088946689276797, 4.458712600427685, 5.856426166887069, 3.227493997226685, 2.7681804086509505, 6.0303356544653015, 11.245445150964063, 29.01518513070073, 18.95075609952391, 1.8658083643472474, 4.552949643851495, 8.528810110309536, 24.3381081775019, 16.88471832928182, 4.890990479190835, 9.237351464590473, 16.064251204965867, 43.59367129602745, 30.009463296290388, 4.06313608815743, 8.949934665824735, 14.265303938258652, 26.548180101486295, 17.110863136972927, 4.010131960837815, 8.802439825768483, 16.44183790154382, 30.59758431451747, 19.734761319311684, 3.103592169771123, 7.257385650541754, 11.39271227859439, 21.99773314707914, 13.915467123658091, 4.733706357200067, 7.615539966157723, 9.83272479491923, 16.594098748327355, 9.80727199217895, 3.6702854751577396, 7.654683043593852, 11.577196941806362, 19.13868910503189, 11.112857758092805, 4.125086647080282, 9.98711069354691, 17.65269259636373, 32.89242103330336, 20.855808436116178, 3.64209839256692, 8.799590249750924, 15.04988638111269, 27.984410010143964, 16.95522578412681, 3.7392424321629623, 8.727804542392764, 14.616992717095155, 26.65619047755532, 17.140832956027637, 3.6856980986259584, 7.53166287464685, 13.610382778753142, 31.636493773205746, 21.17735412849479, 2.159258611513849, 5.179302598254127, 9.407119752607441, 23.211985749998377, 15.083981467480001, 3.310484327009507, 7.9764528794204, 12.899016620349387, 29.536431866821335, 18.736716995901936, 3.8237517513221393, 9.150872479846846, 17.859398303894373, 42.872876258158435, 29.191713283744484, 3.1307991340810233, 6.987637689381422, 16.493392202707266, 46.26437148228328, 31.752651070108207, 6.023536598217199, 13.653872164516933, 23.21705708346415, 41.58626515462165, 26.404700186193693, 7.289226242460115, 16.70562268461191, 29.070899425994952, 58.14554605896537, 37.23201189785071, 5.796628234397344, 13.059935609388411, 24.67180922164482, 59.96208350693328, 39.498957439412116, 1.8693287699067482, 4.135788341780569, 6.305844059405389, 12.193370147916404, 8.201413228818431, 2.8504802111416065, 6.032378479809543, 9.67695658158828, 24.117003619509372, 15.822907192642187, 2.9164781387927246, 5.864014445269319, 14.624605487921993, 44.93051850499556, 30.287821334230664, 4.400346233591313, 9.605525838003766, 18.49698348398367, 35.88676362337636, 23.726532663753304, 6.67357465731887, 14.316230845185949, 27.04859669742404, 54.06194436371187, 34.94235636570192, 3.6741832806824624, 8.866234866741701, 16.38637834494812, 36.88200250029579, 24.739237093894797, 4.223371579178928, 8.911219202828848, 17.58194295896469, 40.997807910259255, 26.38095780156053, 2.968075102424223, 7.471102305595753, 14.582117773395211, 32.88451159116295, 21.57425576080158, 7.143493667336811, 6.707418313823906, 12.429772412947292, 24.939307926249196, 55.15876667457726], [3.3432051713455544, 8.342270539303813, 9.980111652434475, 12.439164394251902, 7.056902271421286, 3.878493611175478, 8.102110702595333, 10.116694195157399, 12.753835794767499, 6.921117609333788, 3.031766161897884, 6.1947734319927665, 6.968044400449147, 12.576072641021515, 7.879021562597921, 4.072715123346876, 7.524187552240707, 10.943940494141863, 23.88534467587092, 15.477828123713378, 2.4036637290914733, 5.884622301066868, 6.95163554548184, 11.287023226516748, 6.693917240497924, 2.702548259879083, 5.481769830848264, 7.153108589509708, 14.841049935273654, 9.572261527336831, 2.6410255719244837, 5.553608623203238, 7.076217621817833, 13.370037418825616, 8.199128082472441, 1.740593292864732, 4.528201433002232, 6.846008011236191, 9.024572796787355, 4.592004537273452, 3.0858245470605556, 6.172814667309012, 8.569740702441694, 18.91952176929577, 12.27526641272839, 2.388058568366092, 5.940450728091704, 8.929328496577275, 13.707991281075687, 8.776988036712941, 2.508677993964013, 6.177301366518838, 9.215433824327603, 13.143559810736805, 7.495602648154661, 1.4741145199483117, 4.3762564441066685, 7.964844815831638, 8.465255795144442, 4.389578924596441, 2.305118899423077, 5.775260802701513, 9.77078113815391, 14.766861209287978, 8.004969180783277, 1.675647522897554, 4.739242992575178, 8.362385352943631, 9.042012046355563, 4.4571778289762545, 1.772439357798443, 4.189007826927068, 5.326420391189115, 9.453799431607354, 5.613210012447271, 3.617202914585005, 7.647328772666513, 11.68178324679795, 17.897991366390333, 11.455549439110507, 2.3799185827174774, 6.199168833255563, 8.119730258156144, 11.100413932961496, 5.874163208962353, 2.4171399256108788, 6.02758736967063, 6.889331789168823, 9.935816960559299, 5.538375203966316, 2.2281163937176456, 4.997282576664674, 5.709806923043923, 6.528804511513123, 3.5646385824961464, 4.693874729252312, 9.538164116649215, 13.111255676587549, 16.810116667235924, 10.078609644219297, 3.8508984179024126, 6.996482094111382, 7.944588700236632, 14.055544151576141, 8.08969671912354, 2.464512798957952, 6.273877557150219, 7.4486733404579235, 9.964114944942828, 5.51672151318805, 2.617517579322739, 7.204534501573535, 9.305989494876904, 11.30382421117442, 6.2591410110692145, 2.5615970776367236, 6.459927829900905, 8.060523194720814, 9.963518103678009, 5.729606772093641, 3.7203445192508857, 7.5555493990276466, 9.471381158212047, 14.328651829488779, 7.848498176469936, 2.9239343731741267, 7.076298360206402, 9.569664021415095, 11.909598492399493, 6.308780455262018, 1.5399137352601444, 4.110572527875703, 4.977779604016259, 6.280103188395779, 3.6160715204242297, 2.3339468720656575, 6.0573987012511505, 8.818389303363272, 10.93839862063787, 6.4794698881967685, 1.7037368522222138, 4.1081828079851315, 5.293087003396276, 6.568685548132296, 3.8068002227223903, 2.7998152856059515, 6.285926534016402, 9.290983689165449, 16.855668561018526, 10.417315537862153, 3.563657560397217, 7.401270559916921, 10.393459296698618, 21.501217251291607, 13.184852522947612, 4.986594144460747, 6.045866493889189, 8.460873992858781, 11.670719489000842, 22.575997036150042], [6.761428736760833, 12.316293976288605, 21.81467762365499, 40.677770178860534, 25.805493855444272, 7.037820562343227, 12.635495989818422, 21.26425654865363, 38.20915351813131, 22.10204600905487, 28.11560406501306, 59.16242608296241, 225.63861700428075, 606.9653802304072, 376.1426519384749, 7.678501325004028, 10.947427075895293, 13.29101878683937, 15.077174476120982, 7.287099237543019, 4.158878131411145, 7.915231357049179, 23.31980719615831, 57.92014981267417, 35.282659061330754, 7.306245163871569, 10.96903177504178, 12.185859152750012, 14.430538664848015, 7.741431570053957, 10.3670947975658, 14.214975433277182, 22.958921194403807, 47.90425547397847, 29.78631809667029, 6.255226023218059, 9.027574711223597, 15.22019815887676, 33.7635147976379, 20.939667291840497, 2.421195467067347, 4.784176592878013, 11.119495213960391, 25.206641850761955, 15.323229392349267, 2.525571581129201, 5.2564212825030365, 9.940994310910948, 10.433211476212545, 5.157419127712383, 5.6248234330880775, 11.67684630587496, 38.803244176616005, 102.42627726972378, 64.11843148577394, 2.0377661452722307, 5.197984075526511, 10.66947341661886, 18.81341807610525, 10.47200400867497, 6.141066178778327, 12.171855142440974, 26.71492292567542, 59.487911883507486, 35.07514928189396, 5.383514056191625, 11.632880853256324, 31.84318217837868, 78.80392077154904, 47.599859249689445, 2.869452449576035, 6.937443448211968, 21.971917700360947, 54.92328187198395, 33.6493679101268, 5.794040704610372, 10.598779271938552, 19.94211270569386, 35.80144343809842, 20.573609266724212, 6.859012309353315, 13.670034980292455, 46.38612137549167, 125.07238546353105, 78.48531089631558, 4.506833430873681, 11.107025005548426, 40.57235166934179, 104.14515299833074, 63.807578042118855, 3.7638589543862935, 8.318322193562123, 19.921981153583964, 45.472324599214076, 27.597955102385054, 5.716807565204423, 9.380736874499386, 11.430998990646842, 16.169274046639472, 9.224844903812398, 5.756231917185729, 11.872241993169533, 22.856588843346902, 54.57988750167872, 34.21733613693879, 10.034451087453688, 21.30403313316996, 72.98101371813016, 192.7815378995648, 118.61572719176338, 2.676050070145475, 6.025418158015116, 19.3272504217788, 48.495336166376255, 29.514071454858712, 2.563575957168483, 5.569471537580355, 8.139115740495038, 11.33768776995356, 6.813765349027336, 7.566604614925857, 15.986225792317184, 56.08977699972115, 150.153426846996, 93.02629161442864, 4.805563391510164, 10.38878117486049, 32.85359730901824, 83.01046687302461, 51.850914565543384, 1.9104749435508586, 4.483242745546507, 9.027129349852517, 10.690748232136233, 5.59200205709794, 2.729560849874413, 6.143963862788479, 19.941462233959673, 49.58854893102985, 30.98520928766418, 5.458487490411205, 11.398020210103889, 38.65859705566661, 102.80207743001478, 63.7659001468399, 4.047271952329297, 8.957807170692409, 21.401827554770914, 46.82266048739817, 27.955079024614392, 4.485022237304274, 9.54677554590008, 18.52883170789491, 33.17734296889605, 19.359054070656672, 9.051333980102019, 9.273460488111008, 15.585306317781821, 29.819763676323266, 72.23040501510012], [16.37210075289177, 32.83395565057326, 128.92853903812568, 377.4064297568836, 267.8297964845663, 1.9395092577532114, 4.45695175358391, 13.27797934669003, 32.61843989970451, 22.227161586057377, 5.521571668563932, 11.166472870904297, 42.02604378753504, 122.2517556064955, 85.56047475297099, 3.8212682560709177, 7.827132924112271, 28.838162976647396, 82.97639543325275, 58.01148596304612, 2.833521751154483, 5.583728831907883, 14.846827510039907, 35.927661448058764, 24.013910015290648, 1.7448280971061676, 3.994002600007454, 13.696362309082911, 35.186868973778786, 24.71618828470401, 10.86148599163527, 21.93098973383025, 84.11046214529233, 245.02967815856536, 172.0263669831952, 6.8830293786542205, 14.41818038469896, 55.868871873455795, 161.57463218979248, 113.22533680491381, 2.4178223529393006, 5.023603388663662, 18.220500143170383, 50.164446003401274, 35.505155512574404, 2.3905998458359923, 5.490904989491459, 18.61653631533651, 49.02241207790169, 33.921931822714264, 8.98482311572838, 17.956969136220998, 69.32927803722183, 199.6988766057079, 143.4139798121121, 2.3430502528014068, 4.873477058681557, 10.922562541567787, 20.623808394289952, 14.645763561201749, 11.115175205084695, 22.91266548028668, 88.52384625215828, 257.3468174533759, 181.4490400730519, 7.391268637705642, 14.188173182958487, 49.79360717803178, 144.3499504705058, 98.38477782647334, 1.1569991331227782, 2.844180154417698, 7.534752907512115, 10.658504089871453, 6.211853839917675, 3.8763109928395214, 7.5003473918951205, 24.181121489655123, 68.00386147722396, 46.697218430123705, 5.108301806663269, 10.234283786378642, 39.491735527518294, 113.64649811607201, 80.33225364655462, 6.722892505063215, 14.17515746090457, 54.42214108738073, 157.193767187182, 110.58647459344103, 15.805693600439968, 32.552754295220794, 128.58224433691097, 374.7369725831085, 265.36450555833557, 8.963890935251166, 18.28190152703348, 70.88621137664987, 206.99481259524765, 145.12508481150428, 5.998331243134022, 12.097950845411988, 47.71028974022541, 138.89214893227035, 98.01744688154162, 3.5226843259250975, 7.374390596234367, 26.22489334303579, 74.29348230895017, 53.4338889828746, 1.5525074100893557, 3.4642206623347596, 10.05145333601525, 25.5765174248474, 17.82815893758445, 2.4738858245312643, 5.147734250755604, 19.115826504288634, 53.33173019988196, 37.46900305109012, 3.692298504601819, 7.54579547827095, 26.348963626019682, 75.58962056676556, 52.18747977838703, 7.673862915665256, 15.602249007731105, 56.369716253507605, 162.8259822553241, 111.84643738722089, 3.4269060763200563, 7.1808849896021485, 26.160948270888817, 74.9854675189831, 51.9610913107056, 5.488443044542524, 11.183957277333356, 42.48341524326465, 123.50894572431308, 86.29616691315125, 1.7497722026244662, 4.308489283575642, 8.150170643928382, 10.254399965005234, 5.994278864633388, 14.64331571796588, 29.56095465714336, 114.09078854451255, 333.6639360109722, 232.34036613499998, 2.0581050706665165, 4.793061320813506, 13.326191656883076, 34.042810484668095, 23.481790029233316, 7.916671813264037, 10.430983775280591, 42.26524241839858, 138.8113566561386, 452.54966948084075], [11.32290412101936, 19.807881852749173, 45.447404035130674, 103.9730805004849, 70.31632994783666, 27.927973378343875, 51.57263548197701, 129.37165715411902, 334.3639864826686, 231.5759629534596, 25.00776709613755, 43.489908605883244, 103.07387966702326, 265.74968752386445, 185.8803858195934, 14.83767567337077, 24.870525312239334, 50.2580994692107, 109.90062767553907, 71.87143330009359, 21.383595039189803, 38.830941161751525, 97.44307493202719, 257.4718479154736, 178.94377637131387, 7.8048319787339215, 13.881621681754172, 34.06795421914116, 91.42875048980716, 63.79767375899693, 12.121931474483839, 21.445312678050783, 51.97433551096268, 140.25597396443433, 98.82760831751322, 10.707377407262673, 19.687692543200466, 48.559076555199304, 126.65736598040407, 87.75503889182525, 16.038994136184947, 28.784942714594138, 72.14217352607135, 191.61048645475535, 133.68032560160134, 18.94790938768136, 34.91721888177514, 87.5984253564682, 220.47200126024654, 152.81552331437845, 13.806511490820338, 25.458925297837446, 62.51322504358077, 166.97258184826669, 116.18047878413485, 14.635773274573722, 26.525967510186195, 66.01884270637515, 183.74029590280844, 128.1774000788829, 17.799860022374087, 32.69727045360254, 80.85886275213825, 217.05701210955365, 150.77135485012442, 15.69367404274413, 27.48607772829149, 70.33287706141564, 185.63878841361148, 130.77192762955093, 23.62714666382952, 43.98449387279499, 109.40942869311672, 273.39314200770036, 188.34414629344855, 18.12814939279138, 33.24415630438204, 81.03578654150134, 198.1403608140087, 135.82823893321995, 9.151524777065145, 15.398936197069874, 38.45590450360449, 103.21963394527162, 71.8832014931767, 17.824807813374367, 31.84666195878066, 80.53457202066073, 209.1994653319485, 145.91273740392649, 23.088952029608315, 45.431581866029774, 113.45572350709156, 257.18168386875163, 171.6635534868019, 16.91468278453992, 35.30027059100587, 84.69068232277668, 156.92552885958298, 89.72008932778597, 16.776004751749387, 29.66925406006472, 73.6336638347004, 191.38027270896458, 132.3082689329486, 1.859117792489156, 4.282263135273696, 8.470011064600692, 13.927624449395067, 7.618893924166961, 29.377334741771993, 54.00956642823671, 134.33434470645852, 346.87430820672296, 240.0373474082194, 4.935526004967555, 11.704266613835866, 29.06966383378848, 51.94780943634116, 30.15105203893944, 17.96866076964206, 31.977121523080207, 79.73215316752317, 210.79001614682196, 147.50273777115615, 23.19026231224223, 43.14656681097882, 108.28294694974814, 276.562573971749, 191.65032298422273, 7.730833717737004, 13.709409219492699, 33.799983087180074, 92.04580238854436, 64.34650926176145, 14.77660305000142, 26.13320545932126, 65.74839347331498, 176.0164070761417, 123.16868229660712, 15.387143022402071, 26.88413743515853, 68.00700287396283, 182.24326386244775, 127.33076744869145, 21.703790966883357, 38.7598176624162, 98.19701687500508, 256.47260010749653, 179.09691288324476, 3.3411275130972267, 7.342346233386284, 17.728797355736134, 29.49034378317072, 19.26092286811516, 7.405018985511128, 11.303369534242474, 28.147078520733082, 59.41248090910145, 125.73065078367647]]\n","[0, 1, 0, 1, 1]\n","Train on 1024 samples, validate on 256 samples\n","Epoch 1/200\n","1024/1024 [==============================] - 1s 996us/sample - loss: 0.6817 - acc: 0.6138 - val_loss: 0.6796 - val_acc: 0.6038\n","Epoch 2/200\n","1024/1024 [==============================] - 0s 178us/sample - loss: 0.6738 - acc: 0.6348 - val_loss: 0.6902 - val_acc: 0.6055\n","Epoch 3/200\n","1024/1024 [==============================] - 0s 181us/sample - loss: 0.6696 - acc: 0.6355 - val_loss: 0.6851 - val_acc: 0.6055\n","Epoch 4/200\n","1024/1024 [==============================] - 0s 193us/sample - loss: 0.6693 - acc: 0.6333 - val_loss: 0.6932 - val_acc: 0.6055\n","Epoch 5/200\n","1024/1024 [==============================] - 0s 179us/sample - loss: 0.6667 - acc: 0.6360 - val_loss: 0.6820 - val_acc: 0.6055\n","Epoch 6/200\n","1024/1024 [==============================] - 0s 179us/sample - loss: 0.6681 - acc: 0.6325 - val_loss: 0.6770 - val_acc: 0.6055\n","Epoch 7/200\n","1024/1024 [==============================] - 0s 176us/sample - loss: 0.6645 - acc: 0.6345 - val_loss: 0.6794 - val_acc: 0.6055\n","Epoch 8/200\n","1024/1024 [==============================] - 0s 174us/sample - loss: 0.6657 - acc: 0.6350 - val_loss: 0.6750 - val_acc: 0.6055\n","Epoch 9/200\n","1024/1024 [==============================] - 0s 175us/sample - loss: 0.6646 - acc: 0.6334 - val_loss: 0.6761 - val_acc: 0.5994\n","Epoch 10/200\n","1024/1024 [==============================] - 0s 172us/sample - loss: 0.6627 - acc: 0.6345 - val_loss: 0.6799 - val_acc: 0.6055\n","Epoch 11/200\n","1024/1024 [==============================] - 0s 172us/sample - loss: 0.6639 - acc: 0.6367 - val_loss: 0.6851 - val_acc: 0.6055\n","Epoch 12/200\n","1024/1024 [==============================] - 0s 191us/sample - loss: 0.6650 - acc: 0.6337 - val_loss: 0.6729 - val_acc: 0.6047\n","Epoch 13/200\n","1024/1024 [==============================] - 0s 175us/sample - loss: 0.6605 - acc: 0.6343 - val_loss: 0.6736 - val_acc: 0.6055\n","Epoch 14/200\n","1024/1024 [==============================] - 0s 180us/sample - loss: 0.6603 - acc: 0.6337 - val_loss: 0.6737 - val_acc: 0.6055\n","Epoch 15/200\n","1024/1024 [==============================] - 0s 169us/sample - loss: 0.6614 - acc: 0.6346 - val_loss: 0.6761 - val_acc: 0.6055\n","Epoch 16/200\n","1024/1024 [==============================] - 0s 167us/sample - loss: 0.6610 - acc: 0.6354 - val_loss: 0.6730 - val_acc: 0.6055\n","Epoch 17/200\n","1024/1024 [==============================] - 0s 174us/sample - loss: 0.6647 - acc: 0.6362 - val_loss: 0.6731 - val_acc: 0.6055\n","Epoch 18/200\n","1024/1024 [==============================] - 0s 174us/sample - loss: 0.6633 - acc: 0.6329 - val_loss: 0.6756 - val_acc: 0.6055\n","Epoch 19/200\n","1024/1024 [==============================] - 0s 168us/sample - loss: 0.6617 - acc: 0.6356 - val_loss: 0.6820 - val_acc: 0.6055\n","Epoch 20/200\n","1024/1024 [==============================] - 0s 174us/sample - loss: 0.6596 - acc: 0.6368 - val_loss: 0.6920 - val_acc: 0.6055\n","Epoch 21/200\n","1024/1024 [==============================] - 0s 173us/sample - loss: 0.6614 - acc: 0.6361 - val_loss: 0.6725 - val_acc: 0.6055\n","Epoch 22/200\n","1024/1024 [==============================] - 0s 172us/sample - loss: 0.6607 - acc: 0.6368 - val_loss: 0.6740 - val_acc: 0.6055\n","Epoch 23/200\n","1024/1024 [==============================] - 0s 195us/sample - loss: 0.6596 - acc: 0.6367 - val_loss: 0.6757 - val_acc: 0.6055\n","Epoch 24/200\n","1024/1024 [==============================] - 0s 171us/sample - loss: 0.6595 - acc: 0.6336 - val_loss: 0.6833 - val_acc: 0.6055\n","Epoch 25/200\n","1024/1024 [==============================] - 0s 176us/sample - loss: 0.6601 - acc: 0.6377 - val_loss: 0.6731 - val_acc: 0.6055\n","Epoch 26/200\n","1024/1024 [==============================] - 0s 172us/sample - loss: 0.6591 - acc: 0.6371 - val_loss: 0.6822 - val_acc: 0.6055\n","Epoch 27/200\n","1024/1024 [==============================] - 0s 166us/sample - loss: 0.6598 - acc: 0.6375 - val_loss: 0.6726 - val_acc: 0.6055\n","Epoch 28/200\n","1024/1024 [==============================] - 0s 170us/sample - loss: 0.6618 - acc: 0.6360 - val_loss: 0.6754 - val_acc: 0.6055\n","Epoch 29/200\n","1024/1024 [==============================] - 0s 188us/sample - loss: 0.6597 - acc: 0.6367 - val_loss: 0.6774 - val_acc: 0.6055\n","Epoch 30/200\n","1024/1024 [==============================] - 0s 182us/sample - loss: 0.6588 - acc: 0.6375 - val_loss: 0.6737 - val_acc: 0.6006\n","Epoch 31/200\n","1024/1024 [==============================] - 0s 190us/sample - loss: 0.6576 - acc: 0.6359 - val_loss: 0.6735 - val_acc: 0.6055\n","Epoch 32/200\n","1024/1024 [==============================] - 0s 184us/sample - loss: 0.6590 - acc: 0.6364 - val_loss: 0.6809 - val_acc: 0.6055\n","Epoch 33/200\n","1024/1024 [==============================] - 0s 170us/sample - loss: 0.6590 - acc: 0.6368 - val_loss: 0.6721 - val_acc: 0.6033\n","Epoch 34/200\n","1024/1024 [==============================] - 0s 187us/sample - loss: 0.6585 - acc: 0.6372 - val_loss: 0.6718 - val_acc: 0.6055\n","Epoch 35/200\n","1024/1024 [==============================] - 0s 176us/sample - loss: 0.6599 - acc: 0.6375 - val_loss: 0.6754 - val_acc: 0.6055\n","Epoch 36/200\n","1024/1024 [==============================] - 0s 170us/sample - loss: 0.6583 - acc: 0.6353 - val_loss: 0.6802 - val_acc: 0.6055\n","Epoch 37/200\n","1024/1024 [==============================] - 0s 173us/sample - loss: 0.6569 - acc: 0.6373 - val_loss: 0.6741 - val_acc: 0.6023\n","Epoch 38/200\n","1024/1024 [==============================] - 0s 167us/sample - loss: 0.6576 - acc: 0.6368 - val_loss: 0.6718 - val_acc: 0.6055\n","Epoch 39/200\n","1024/1024 [==============================] - 0s 172us/sample - loss: 0.6581 - acc: 0.6345 - val_loss: 0.6763 - val_acc: 0.6055\n","Epoch 40/200\n","1024/1024 [==============================] - 0s 195us/sample - loss: 0.6584 - acc: 0.6377 - val_loss: 0.6769 - val_acc: 0.6055\n","Epoch 41/200\n","1024/1024 [==============================] - 0s 178us/sample - loss: 0.6587 - acc: 0.6368 - val_loss: 0.6718 - val_acc: 0.6055\n","Epoch 42/200\n","1024/1024 [==============================] - 0s 172us/sample - loss: 0.6573 - acc: 0.6374 - val_loss: 0.6715 - val_acc: 0.6055\n","Epoch 43/200\n","1024/1024 [==============================] - 0s 169us/sample - loss: 0.6569 - acc: 0.6377 - val_loss: 0.6789 - val_acc: 0.6055\n","Epoch 44/200\n","1024/1024 [==============================] - 0s 168us/sample - loss: 0.6588 - acc: 0.6372 - val_loss: 0.6728 - val_acc: 0.6055\n","Epoch 45/200\n","1024/1024 [==============================] - 0s 188us/sample - loss: 0.6585 - acc: 0.6373 - val_loss: 0.6745 - val_acc: 0.6055\n","Epoch 46/200\n","1024/1024 [==============================] - 0s 180us/sample - loss: 0.6566 - acc: 0.6360 - val_loss: 0.6769 - val_acc: 0.6055\n","Epoch 47/200\n","1024/1024 [==============================] - 0s 174us/sample - loss: 0.6560 - acc: 0.6377 - val_loss: 0.6715 - val_acc: 0.6055\n","Epoch 48/200\n","1024/1024 [==============================] - 0s 173us/sample - loss: 0.6584 - acc: 0.6377 - val_loss: 0.6710 - val_acc: 0.6055\n","Epoch 49/200\n","1024/1024 [==============================] - 0s 173us/sample - loss: 0.6566 - acc: 0.6377 - val_loss: 0.6718 - val_acc: 0.6030\n","Epoch 50/200\n","1024/1024 [==============================] - 0s 176us/sample - loss: 0.6577 - acc: 0.6375 - val_loss: 0.6724 - val_acc: 0.6055\n","Epoch 51/200\n","1024/1024 [==============================] - 0s 197us/sample - loss: 0.6571 - acc: 0.6377 - val_loss: 0.6721 - val_acc: 0.6055\n","Epoch 52/200\n","1024/1024 [==============================] - 0s 181us/sample - loss: 0.6574 - acc: 0.6377 - val_loss: 0.6716 - val_acc: 0.6055\n","Epoch 53/200\n","1024/1024 [==============================] - 0s 177us/sample - loss: 0.6557 - acc: 0.6377 - val_loss: 0.6884 - val_acc: 0.6055\n","Epoch 54/200\n","1024/1024 [==============================] - 0s 171us/sample - loss: 0.6572 - acc: 0.6377 - val_loss: 0.6776 - val_acc: 0.6055\n","Epoch 55/200\n","1024/1024 [==============================] - 0s 176us/sample - loss: 0.6562 - acc: 0.6377 - val_loss: 0.6731 - val_acc: 0.6055\n","Epoch 56/200\n","1024/1024 [==============================] - 0s 195us/sample - loss: 0.6566 - acc: 0.6377 - val_loss: 0.6776 - val_acc: 0.6055\n","Epoch 57/200\n","1024/1024 [==============================] - 0s 171us/sample - loss: 0.6572 - acc: 0.6377 - val_loss: 0.6712 - val_acc: 0.6055\n","Epoch 58/200\n","1024/1024 [==============================] - 0s 172us/sample - loss: 0.6574 - acc: 0.6377 - val_loss: 0.6732 - val_acc: 0.6055\n","Epoch 59/200\n","1024/1024 [==============================] - 0s 169us/sample - loss: 0.6566 - acc: 0.6377 - val_loss: 0.6740 - val_acc: 0.6055\n","Epoch 60/200\n","1024/1024 [==============================] - 0s 164us/sample - loss: 0.6563 - acc: 0.6377 - val_loss: 0.6710 - val_acc: 0.6055\n","Epoch 61/200\n","1024/1024 [==============================] - 0s 176us/sample - loss: 0.6552 - acc: 0.6370 - val_loss: 0.6905 - val_acc: 0.6055\n","Epoch 62/200\n","1024/1024 [==============================] - 0s 182us/sample - loss: 0.6579 - acc: 0.6377 - val_loss: 0.6732 - val_acc: 0.6055\n","Epoch 63/200\n","1024/1024 [==============================] - 0s 176us/sample - loss: 0.6566 - acc: 0.6377 - val_loss: 0.6713 - val_acc: 0.6055\n","Epoch 64/200\n","1024/1024 [==============================] - 0s 180us/sample - loss: 0.6565 - acc: 0.6377 - val_loss: 0.6713 - val_acc: 0.6055\n","Epoch 65/200\n","1024/1024 [==============================] - 0s 195us/sample - loss: 0.6564 - acc: 0.6377 - val_loss: 0.6732 - val_acc: 0.6055\n","Epoch 66/200\n","1024/1024 [==============================] - 0s 188us/sample - loss: 0.6573 - acc: 0.6377 - val_loss: 0.6712 - val_acc: 0.6055\n","Epoch 67/200\n","1024/1024 [==============================] - 0s 204us/sample - loss: 0.6572 - acc: 0.6377 - val_loss: 0.6716 - val_acc: 0.6055\n","Epoch 68/200\n","1024/1024 [==============================] - 0s 199us/sample - loss: 0.6569 - acc: 0.6377 - val_loss: 0.6741 - val_acc: 0.6055\n","Epoch 69/200\n","1024/1024 [==============================] - 0s 188us/sample - loss: 0.6563 - acc: 0.6377 - val_loss: 0.6721 - val_acc: 0.6055\n","Epoch 70/200\n","1024/1024 [==============================] - 0s 182us/sample - loss: 0.6568 - acc: 0.6377 - val_loss: 0.6719 - val_acc: 0.6055\n","Epoch 71/200\n","1024/1024 [==============================] - 0s 173us/sample - loss: 0.6555 - acc: 0.6377 - val_loss: 0.6722 - val_acc: 0.6055\n","Epoch 72/200\n","1024/1024 [==============================] - 0s 188us/sample - loss: 0.6567 - acc: 0.6377 - val_loss: 0.6715 - val_acc: 0.6055\n","Epoch 73/200\n","1024/1024 [==============================] - 0s 182us/sample - loss: 0.6555 - acc: 0.6377 - val_loss: 0.6793 - val_acc: 0.6055\n","Epoch 74/200\n","1024/1024 [==============================] - 0s 175us/sample - loss: 0.6570 - acc: 0.6377 - val_loss: 0.6717 - val_acc: 0.6055\n","Epoch 75/200\n","1024/1024 [==============================] - 0s 169us/sample - loss: 0.6566 - acc: 0.6377 - val_loss: 0.6714 - val_acc: 0.6055\n","Epoch 76/200\n","1024/1024 [==============================] - 0s 178us/sample - loss: 0.6561 - acc: 0.6377 - val_loss: 0.6740 - val_acc: 0.6055\n","Epoch 77/200\n","1024/1024 [==============================] - 0s 170us/sample - loss: 0.6552 - acc: 0.6377 - val_loss: 0.6759 - val_acc: 0.6055\n","Epoch 78/200\n","1024/1024 [==============================] - 0s 183us/sample - loss: 0.6560 - acc: 0.6377 - val_loss: 0.6716 - val_acc: 0.6055\n","Epoch 79/200\n","1024/1024 [==============================] - 0s 183us/sample - loss: 0.6561 - acc: 0.6377 - val_loss: 0.6738 - val_acc: 0.6055\n","Epoch 80/200\n","1024/1024 [==============================] - 0s 185us/sample - loss: 0.6562 - acc: 0.6377 - val_loss: 0.6732 - val_acc: 0.6055\n","Epoch 81/200\n","1024/1024 [==============================] - 0s 182us/sample - loss: 0.6563 - acc: 0.6377 - val_loss: 0.6727 - val_acc: 0.6055\n","Epoch 82/200\n","1024/1024 [==============================] - 0s 181us/sample - loss: 0.6565 - acc: 0.6377 - val_loss: 0.6717 - val_acc: 0.6055\n","Epoch 83/200\n","1024/1024 [==============================] - 0s 188us/sample - loss: 0.6560 - acc: 0.6377 - val_loss: 0.6715 - val_acc: 0.6055\n","Epoch 84/200\n","1024/1024 [==============================] - 0s 179us/sample - loss: 0.6561 - acc: 0.6377 - val_loss: 0.6728 - val_acc: 0.6055\n","Epoch 85/200\n","1024/1024 [==============================] - 0s 176us/sample - loss: 0.6558 - acc: 0.6377 - val_loss: 0.6766 - val_acc: 0.6055\n","Epoch 86/200\n","1024/1024 [==============================] - 0s 169us/sample - loss: 0.6561 - acc: 0.6377 - val_loss: 0.6725 - val_acc: 0.6055\n","Epoch 87/200\n","1024/1024 [==============================] - 0s 174us/sample - loss: 0.6559 - acc: 0.6377 - val_loss: 0.6727 - val_acc: 0.6055\n","Epoch 88/200\n","1024/1024 [==============================] - 0s 175us/sample - loss: 0.6555 - acc: 0.6377 - val_loss: 0.6740 - val_acc: 0.6055\n","Epoch 89/200\n","1024/1024 [==============================] - 0s 197us/sample - loss: 0.6560 - acc: 0.6377 - val_loss: 0.6722 - val_acc: 0.6055\n","Epoch 90/200\n","1024/1024 [==============================] - 0s 177us/sample - loss: 0.6558 - acc: 0.6377 - val_loss: 0.6754 - val_acc: 0.6055\n","Epoch 91/200\n","1024/1024 [==============================] - 0s 190us/sample - loss: 0.6552 - acc: 0.6377 - val_loss: 0.6714 - val_acc: 0.6055\n","Epoch 92/200\n","1024/1024 [==============================] - 0s 174us/sample - loss: 0.6555 - acc: 0.6377 - val_loss: 0.6716 - val_acc: 0.6055\n","Epoch 93/200\n","1024/1024 [==============================] - 0s 172us/sample - loss: 0.6563 - acc: 0.6377 - val_loss: 0.6721 - val_acc: 0.6055\n","Epoch 94/200\n","1024/1024 [==============================] - 0s 175us/sample - loss: 0.6552 - acc: 0.6377 - val_loss: 0.6754 - val_acc: 0.6055\n","Epoch 95/200\n","1024/1024 [==============================] - 0s 169us/sample - loss: 0.6554 - acc: 0.6377 - val_loss: 0.6740 - val_acc: 0.6055\n","Epoch 96/200\n","1024/1024 [==============================] - 0s 173us/sample - loss: 0.6557 - acc: 0.6377 - val_loss: 0.6729 - val_acc: 0.6055\n","Epoch 97/200\n","1024/1024 [==============================] - 0s 170us/sample - loss: 0.6558 - acc: 0.6377 - val_loss: 0.6749 - val_acc: 0.6055\n","Epoch 98/200\n","1024/1024 [==============================] - 0s 171us/sample - loss: 0.6561 - acc: 0.6377 - val_loss: 0.6731 - val_acc: 0.6055\n","Epoch 99/200\n","1024/1024 [==============================] - 0s 179us/sample - loss: 0.6552 - acc: 0.6377 - val_loss: 0.6719 - val_acc: 0.6055\n","Epoch 100/200\n","1024/1024 [==============================] - 0s 189us/sample - loss: 0.6557 - acc: 0.6377 - val_loss: 0.6714 - val_acc: 0.6055\n","Epoch 101/200\n","1024/1024 [==============================] - 0s 177us/sample - loss: 0.6557 - acc: 0.6377 - val_loss: 0.6722 - val_acc: 0.6055\n","Epoch 102/200\n","1024/1024 [==============================] - 0s 166us/sample - loss: 0.6556 - acc: 0.6377 - val_loss: 0.6717 - val_acc: 0.6055\n","Epoch 103/200\n","1024/1024 [==============================] - 0s 176us/sample - loss: 0.6557 - acc: 0.6377 - val_loss: 0.6726 - val_acc: 0.6055\n","Epoch 104/200\n","1024/1024 [==============================] - 0s 166us/sample - loss: 0.6548 - acc: 0.6377 - val_loss: 0.6714 - val_acc: 0.6055\n","Epoch 105/200\n","1024/1024 [==============================] - 0s 177us/sample - loss: 0.6553 - acc: 0.6377 - val_loss: 0.6738 - val_acc: 0.6055\n","Epoch 106/200\n","1024/1024 [==============================] - 0s 170us/sample - loss: 0.6556 - acc: 0.6377 - val_loss: 0.6727 - val_acc: 0.6055\n","Epoch 107/200\n","1024/1024 [==============================] - 0s 175us/sample - loss: 0.6558 - acc: 0.6377 - val_loss: 0.6719 - val_acc: 0.6055\n","Epoch 108/200\n","1024/1024 [==============================] - 0s 189us/sample - loss: 0.6554 - acc: 0.6377 - val_loss: 0.6742 - val_acc: 0.6055\n","Epoch 109/200\n","1024/1024 [==============================] - 0s 182us/sample - loss: 0.6560 - acc: 0.6377 - val_loss: 0.6727 - val_acc: 0.6055\n","Epoch 110/200\n","1024/1024 [==============================] - 0s 178us/sample - loss: 0.6556 - acc: 0.6377 - val_loss: 0.6732 - val_acc: 0.6055\n","Epoch 111/200\n","1024/1024 [==============================] - 0s 179us/sample - loss: 0.6558 - acc: 0.6377 - val_loss: 0.6729 - val_acc: 0.6055\n","Epoch 112/200\n","1024/1024 [==============================] - 0s 171us/sample - loss: 0.6554 - acc: 0.6377 - val_loss: 0.6735 - val_acc: 0.6055\n","Epoch 113/200\n","1024/1024 [==============================] - 0s 179us/sample - loss: 0.6557 - acc: 0.6377 - val_loss: 0.6732 - val_acc: 0.6055\n","Epoch 114/200\n","1024/1024 [==============================] - 0s 172us/sample - loss: 0.6558 - acc: 0.6377 - val_loss: 0.6731 - val_acc: 0.6055\n","Epoch 115/200\n","1024/1024 [==============================] - 0s 169us/sample - loss: 0.6553 - acc: 0.6377 - val_loss: 0.6726 - val_acc: 0.6055\n","Epoch 116/200\n","1024/1024 [==============================] - 0s 186us/sample - loss: 0.6554 - acc: 0.6377 - val_loss: 0.6719 - val_acc: 0.6055\n","Epoch 117/200\n","1024/1024 [==============================] - 0s 180us/sample - loss: 0.6553 - acc: 0.6377 - val_loss: 0.6737 - val_acc: 0.6055\n","Epoch 118/200\n","1024/1024 [==============================] - 0s 170us/sample - loss: 0.6555 - acc: 0.6377 - val_loss: 0.6740 - val_acc: 0.6055\n","Epoch 119/200\n","1024/1024 [==============================] - 0s 171us/sample - loss: 0.6553 - acc: 0.6377 - val_loss: 0.6731 - val_acc: 0.6055\n","Epoch 120/200\n","1024/1024 [==============================] - 0s 177us/sample - loss: 0.6554 - acc: 0.6377 - val_loss: 0.6727 - val_acc: 0.6055\n","Epoch 121/200\n","1024/1024 [==============================] - 0s 199us/sample - loss: 0.6552 - acc: 0.6377 - val_loss: 0.6733 - val_acc: 0.6055\n","Epoch 122/200\n","1024/1024 [==============================] - 0s 184us/sample - loss: 0.6551 - acc: 0.6377 - val_loss: 0.6721 - val_acc: 0.6055\n","Epoch 123/200\n","1024/1024 [==============================] - 0s 174us/sample - loss: 0.6556 - acc: 0.6377 - val_loss: 0.6727 - val_acc: 0.6055\n","Epoch 124/200\n","1024/1024 [==============================] - 0s 174us/sample - loss: 0.6553 - acc: 0.6377 - val_loss: 0.6722 - val_acc: 0.6055\n","Epoch 125/200\n","1024/1024 [==============================] - 0s 173us/sample - loss: 0.6557 - acc: 0.6377 - val_loss: 0.6730 - val_acc: 0.6055\n","Epoch 126/200\n","1024/1024 [==============================] - 0s 177us/sample - loss: 0.6552 - acc: 0.6377 - val_loss: 0.6736 - val_acc: 0.6055\n","Epoch 127/200\n","1024/1024 [==============================] - 0s 187us/sample - loss: 0.6554 - acc: 0.6377 - val_loss: 0.6727 - val_acc: 0.6055\n","Epoch 128/200\n","1024/1024 [==============================] - 0s 175us/sample - loss: 0.6555 - acc: 0.6377 - val_loss: 0.6727 - val_acc: 0.6055\n","Epoch 129/200\n","1024/1024 [==============================] - 0s 180us/sample - loss: 0.6549 - acc: 0.6377 - val_loss: 0.6720 - val_acc: 0.6055\n","Epoch 130/200\n","1024/1024 [==============================] - 0s 172us/sample - loss: 0.6557 - acc: 0.6377 - val_loss: 0.6731 - val_acc: 0.6055\n","Epoch 131/200\n","1024/1024 [==============================] - 0s 174us/sample - loss: 0.6552 - acc: 0.6377 - val_loss: 0.6735 - val_acc: 0.6055\n","Epoch 132/200\n","1024/1024 [==============================] - 0s 171us/sample - loss: 0.6554 - acc: 0.6377 - val_loss: 0.6733 - val_acc: 0.6055\n","Epoch 133/200\n","1024/1024 [==============================] - 0s 190us/sample - loss: 0.6554 - acc: 0.6377 - val_loss: 0.6727 - val_acc: 0.6055\n","Epoch 134/200\n","1024/1024 [==============================] - 0s 178us/sample - loss: 0.6551 - acc: 0.6377 - val_loss: 0.6736 - val_acc: 0.6055\n","Epoch 135/200\n","1024/1024 [==============================] - 0s 170us/sample - loss: 0.6551 - acc: 0.6377 - val_loss: 0.6742 - val_acc: 0.6055\n","Epoch 136/200\n","1024/1024 [==============================] - 0s 179us/sample - loss: 0.6553 - acc: 0.6377 - val_loss: 0.6732 - val_acc: 0.6055\n","Epoch 137/200\n","1024/1024 [==============================] - 0s 173us/sample - loss: 0.6553 - acc: 0.6377 - val_loss: 0.6732 - val_acc: 0.6055\n","Epoch 138/200\n","1024/1024 [==============================] - 0s 178us/sample - loss: 0.6554 - acc: 0.6377 - val_loss: 0.6735 - val_acc: 0.6055\n","Epoch 139/200\n","1024/1024 [==============================] - 0s 172us/sample - loss: 0.6553 - acc: 0.6377 - val_loss: 0.6724 - val_acc: 0.6055\n","Epoch 140/200\n","1024/1024 [==============================] - 0s 172us/sample - loss: 0.6552 - acc: 0.6377 - val_loss: 0.6721 - val_acc: 0.6055\n","Epoch 141/200\n","1024/1024 [==============================] - 0s 200us/sample - loss: 0.6554 - acc: 0.6377 - val_loss: 0.6724 - val_acc: 0.6055\n","Epoch 142/200\n","1024/1024 [==============================] - 0s 198us/sample - loss: 0.6552 - acc: 0.6377 - val_loss: 0.6720 - val_acc: 0.6055\n","Epoch 143/200\n","1024/1024 [==============================] - 0s 189us/sample - loss: 0.6551 - acc: 0.6377 - val_loss: 0.6741 - val_acc: 0.6055\n","Epoch 144/200\n","1024/1024 [==============================] - 0s 209us/sample - loss: 0.6553 - acc: 0.6377 - val_loss: 0.6735 - val_acc: 0.6055\n","Epoch 145/200\n","1024/1024 [==============================] - 0s 187us/sample - loss: 0.6554 - acc: 0.6377 - val_loss: 0.6732 - val_acc: 0.6055\n","Epoch 146/200\n","1024/1024 [==============================] - 0s 189us/sample - loss: 0.6551 - acc: 0.6377 - val_loss: 0.6717 - val_acc: 0.6055\n","Epoch 147/200\n","1024/1024 [==============================] - 0s 221us/sample - loss: 0.6552 - acc: 0.6377 - val_loss: 0.6726 - val_acc: 0.6055\n","Epoch 148/200\n","1024/1024 [==============================] - 0s 177us/sample - loss: 0.6551 - acc: 0.6377 - val_loss: 0.6736 - val_acc: 0.6055\n","Epoch 149/200\n","1024/1024 [==============================] - 0s 184us/sample - loss: 0.6553 - acc: 0.6377 - val_loss: 0.6728 - val_acc: 0.6055\n","Epoch 150/200\n","1024/1024 [==============================] - 0s 180us/sample - loss: 0.6552 - acc: 0.6377 - val_loss: 0.6735 - val_acc: 0.6055\n","Epoch 151/200\n","1024/1024 [==============================] - 0s 167us/sample - loss: 0.6555 - acc: 0.6377 - val_loss: 0.6732 - val_acc: 0.6055\n","Epoch 152/200\n"," 736/1024 [====================>.........] - ETA: 0s - loss: 0.6630 - acc: 0.6236"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-64a9350b6260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY0_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY0_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Arrosal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"UzOvHuktEwg4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"7f7eeb3e-fb81-423e-f319-f900be747ef6","executionInfo":{"status":"ok","timestamp":1582045749628,"user_tz":-120,"elapsed":2030,"user":{"displayName":"Peter Maged","photoUrl":"","userId":"06037909729134877604"}}},"source":["model.evaluate(X0_test, Y0_test)\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["256/256 [==============================] - 0s 105us/sample - loss: 0.6435 - acc: 0.6602\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.6434658169746399, 0.66015625]"]},"metadata":{"tags":[]},"execution_count":22}]}]}